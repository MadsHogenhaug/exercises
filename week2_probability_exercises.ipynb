{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Probability Fundamentals - Exercises\n",
    "\n",
    "**Goal**: Build a solid intuition for probability, conditional probability, and Bayes' theorem through hands-on implementation.\n",
    "\n",
    "**Milestone**: Can explain what P(A|B) means and compute it manually.\n",
    "\n",
    "**Key Resources for this week**:\n",
    "- StatQuest: Probability vs. Likelihood\n",
    "- StatQuest: Bayes' Theorem\n",
    "- 3Blue1Brown: Bayes theorem (visual intuition)\n",
    "- Naked Statistics chapters 5-7\n",
    "- ISLR Chapter 2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Run this first\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Probability Basics\n",
    "\n",
    "### Exercise 1.1: Empirical vs. Theoretical Probability\n",
    "\n",
    "One of the most fundamental ideas in probability: as you run more trials, the empirical (observed) probability converges to the theoretical probability.\n",
    "\n",
    "**Task**: Simulate coin flips and show how the proportion of heads converges to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_coin_flips(n_flips, p_heads=0.5):\n",
    "    \"\"\"\n",
    "    Simulate n coin flips and return the running proportion of heads.\n",
    "    \n",
    "    Returns:\n",
    "        Array of length n_flips where element i is the proportion of heads\n",
    "        after i+1 flips.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Hint: np.random.binomial(1, p_heads, n_flips) gives 1s and 0s\n",
    "    # Then use np.cumsum to get running total\n",
    "    pass\n",
    "\n",
    "\n",
    "# Simulate and visualize\n",
    "n_flips = 10000\n",
    "running_proportions = simulate_coin_flips(n_flips)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(range(1, n_flips + 1), running_proportions, alpha=0.7)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', label='Theoretical probability (0.5)')\n",
    "plt.xscale('log')  # Log scale to see early convergence better\n",
    "plt.xlabel('Number of Flips')\n",
    "plt.ylabel('Proportion of Heads')\n",
    "plt.title('Law of Large Numbers: Convergence to True Probability')\n",
    "plt.legend()\n",
    "plt.ylim(0.3, 0.7)\n",
    "plt.show()\n",
    "\n",
    "print(f\"After 100 flips: {running_proportions[99]:.3f}\")\n",
    "print(f\"After 1000 flips: {running_proportions[999]:.3f}\")\n",
    "print(f\"After 10000 flips: {running_proportions[9999]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Joint and Marginal Probabilities\n",
    "\n",
    "Let's work with a concrete dataset to understand joint and marginal probabilities.\n",
    "\n",
    "**Scenario**: A company tracks employee data including department and whether they work remotely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset of 1000 employees\n",
    "np.random.seed(42)\n",
    "\n",
    "n_employees = 1000\n",
    "\n",
    "# Departments with different sizes\n",
    "departments = np.random.choice(\n",
    "    ['Engineering', 'Sales', 'Marketing', 'HR'],\n",
    "    size=n_employees,\n",
    "    p=[0.4, 0.3, 0.2, 0.1]  # Engineering is largest\n",
    ")\n",
    "\n",
    "# Remote work depends on department\n",
    "remote_probs = {'Engineering': 0.7, 'Sales': 0.3, 'Marketing': 0.5, 'HR': 0.2}\n",
    "remote = np.array([np.random.random() < remote_probs[dept] for dept in departments])\n",
    "\n",
    "employees = pd.DataFrame({\n",
    "    'department': departments,\n",
    "    'remote': remote\n",
    "})\n",
    "\n",
    "print(\"First 10 employees:\")\n",
    "print(employees.head(10))\n",
    "print(f\"\\nTotal employees: {len(employees)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Task 1: Calculate MARGINAL probabilities\n",
    "# P(Engineering), P(Sales), P(Marketing), P(HR)\n",
    "# P(Remote), P(Not Remote)\n",
    "\n",
    "print(\"Marginal Probabilities:\")\n",
    "print(\"\\nP(Department):\")\n",
    "# TODO: Calculate probability of each department\n",
    "\n",
    "print(\"\\nP(Remote):\")\n",
    "# TODO: Calculate probability of remote vs not remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Calculate JOINT probabilities\n",
    "# P(Engineering AND Remote), P(Engineering AND Not Remote), etc.\n",
    "\n",
    "# Create a joint probability table (also called contingency table)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Hint: pd.crosstab can help, then divide by total\n",
    "joint_counts = pd.crosstab(employees['department'], employees['remote'])\n",
    "joint_probs = # TODO: Convert counts to probabilities\n",
    "\n",
    "print(\"Joint Probability Table P(Department, Remote):\")\n",
    "print(joint_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Verify the relationship between joint and marginal probabilities\n",
    "# The sum of joint probabilities across one variable gives the marginal of the other\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Show that: sum of P(Dept=X, Remote=True) + P(Dept=X, Remote=False) = P(Dept=X)\n",
    "# Show that: sum of P(Dept=any, Remote=True) = P(Remote=True)\n",
    "\n",
    "print(\"Verification that row sums = marginal P(Department):\")\n",
    "# TODO\n",
    "\n",
    "print(\"\\nVerification that column sums = marginal P(Remote):\")\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Conditional Probability\n",
    "\n",
    "### The Key Formula:\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "\"The probability of A given B equals the probability of both A and B, divided by the probability of B.\"\n",
    "\n",
    "### Exercise 2.1: Calculate Conditional Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our employee dataset\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Question 1: What is P(Remote | Engineering)?\n",
    "# \"Given someone is in Engineering, what's the probability they're remote?\"\n",
    "\n",
    "# Method 1: Direct counting\n",
    "n_engineering = # TODO\n",
    "n_engineering_and_remote = # TODO\n",
    "p_remote_given_engineering_v1 = # TODO\n",
    "\n",
    "# Method 2: Using the formula P(A|B) = P(Aâˆ©B) / P(B)\n",
    "p_engineering = # TODO (marginal)\n",
    "p_engineering_and_remote = # TODO (joint)\n",
    "p_remote_given_engineering_v2 = # TODO\n",
    "\n",
    "print(\"P(Remote | Engineering):\")\n",
    "print(f\"  Method 1 (direct counting): {p_remote_given_engineering_v1:.4f}\")\n",
    "print(f\"  Method 2 (using formula): {p_remote_given_engineering_v2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: Calculate P(Remote | Department) for ALL departments\n",
    "\n",
    "def calculate_conditional_prob(df, given_col, given_val, target_col, target_val):\n",
    "    \"\"\"\n",
    "    Calculate P(target_col = target_val | given_col = given_val)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "\n",
    "print(\"P(Remote=True | Department):\")\n",
    "for dept in ['Engineering', 'Sales', 'Marketing', 'HR']:\n",
    "    prob = calculate_conditional_prob(employees, 'department', dept, 'remote', True)\n",
    "    print(f\"  {dept}: {prob:.4f}\")\n",
    "\n",
    "print(\"\\nRecall the true probabilities we set:\")\n",
    "for dept, prob in remote_probs.items():\n",
    "    print(f\"  {dept}: {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: The Difference Between P(A|B) and P(B|A)\n",
    "\n",
    "This is a crucial concept that many people confuse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Calculate both:\n",
    "# P(Remote | Engineering) - \"Given Engineering, probability of Remote\"\n",
    "# P(Engineering | Remote) - \"Given Remote, probability of Engineering\"\n",
    "\n",
    "p_remote_given_engineering = # TODO\n",
    "p_engineering_given_remote = # TODO\n",
    "\n",
    "print(f\"P(Remote | Engineering) = {p_remote_given_engineering:.4f}\")\n",
    "print(f\"P(Engineering | Remote) = {p_engineering_given_remote:.4f}\")\n",
    "print(f\"\\nThese are very different!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Explain in plain English why these two probabilities are different. What question does each one answer?\n",
    "\n",
    "**Your answer**:\n",
    "- P(Remote | Engineering) answers: \n",
    "- P(Engineering | Remote) answers: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3: Independence\n",
    "\n",
    "Two events A and B are **independent** if: P(A|B) = P(A)\n",
    "\n",
    "In other words, knowing B doesn't change the probability of A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to our dataset: employee_id is odd or even\n",
    "employees['odd_id'] = np.arange(len(employees)) % 2 == 1\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Test 1: Is 'remote' independent of 'department'?\n",
    "# Check if P(Remote) â‰ˆ P(Remote | Engineering)\n",
    "\n",
    "p_remote = # TODO\n",
    "p_remote_given_eng = # TODO\n",
    "\n",
    "print(\"Test for independence between Remote and Department:\")\n",
    "print(f\"  P(Remote) = {p_remote:.4f}\")\n",
    "print(f\"  P(Remote | Engineering) = {p_remote_given_eng:.4f}\")\n",
    "print(f\"  Independent? {np.isclose(p_remote, p_remote_given_eng, atol=0.05)}\")\n",
    "\n",
    "# Test 2: Is 'remote' independent of 'odd_id'?\n",
    "p_remote_given_odd = # TODO\n",
    "\n",
    "print(\"\\nTest for independence between Remote and Odd ID:\")\n",
    "print(f\"  P(Remote) = {p_remote:.4f}\")\n",
    "print(f\"  P(Remote | Odd ID) = {p_remote_given_odd:.4f}\")\n",
    "print(f\"  Independent? {np.isclose(p_remote, p_remote_given_odd, atol=0.05)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Bayes' Theorem\n",
    "\n",
    "### The Formula:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    "Or with the law of total probability for P(B):\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B|A) \\cdot P(A) + P(B|\\neg A) \\cdot P(\\neg A)}$$\n",
    "\n",
    "### Exercise 3.1: Medical Testing (Classic Example)\n",
    "\n",
    "A disease affects 1% of the population. A test for the disease has:\n",
    "- 99% sensitivity (true positive rate): P(Positive | Disease) = 0.99\n",
    "- 95% specificity (true negative rate): P(Negative | No Disease) = 0.95\n",
    "\n",
    "**Question**: If someone tests positive, what's the probability they have the disease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given information\n",
    "p_disease = 0.01  # Prior: P(Disease)\n",
    "p_no_disease = 1 - p_disease  # P(No Disease)\n",
    "\n",
    "p_positive_given_disease = 0.99  # Sensitivity\n",
    "p_negative_given_no_disease = 0.95  # Specificity\n",
    "p_positive_given_no_disease = 1 - p_negative_given_no_disease  # False positive rate\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 1: Calculate P(Positive) using law of total probability\n",
    "# P(Positive) = P(Positive|Disease)P(Disease) + P(Positive|No Disease)P(No Disease)\n",
    "p_positive = # TODO\n",
    "\n",
    "# Step 2: Apply Bayes' theorem to find P(Disease | Positive)\n",
    "p_disease_given_positive = # TODO\n",
    "\n",
    "print(\"Medical Test Analysis:\")\n",
    "print(f\"  Prior probability of disease: {p_disease:.2%}\")\n",
    "print(f\"  P(Test Positive): {p_positive:.4f}\")\n",
    "print(f\"  P(Disease | Positive Test): {p_disease_given_positive:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: The result might surprise you! Why is P(Disease | Positive) so much lower than the test's 99% sensitivity? Explain intuitively.\n",
    "\n",
    "**Your answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with a simulation of 100,000 people\n",
    "\n",
    "n_people = 100000\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Calculate expected counts in each category\n",
    "\n",
    "n_with_disease = int(n_people * p_disease)\n",
    "n_without_disease = n_people - n_with_disease\n",
    "\n",
    "# Of those with disease, how many test positive?\n",
    "n_true_positives = # TODO\n",
    "\n",
    "# Of those without disease, how many test positive (false positives)?\n",
    "n_false_positives = # TODO\n",
    "\n",
    "# Total positives\n",
    "n_total_positives = n_true_positives + n_false_positives\n",
    "\n",
    "print(f\"Out of {n_people:,} people:\")\n",
    "print(f\"  {n_with_disease:,} have the disease\")\n",
    "print(f\"  {n_without_disease:,} don't have the disease\")\n",
    "print(f\"\\nPositive tests:\")\n",
    "print(f\"  {n_true_positives:,} true positives (actually sick)\")\n",
    "print(f\"  {n_false_positives:,} false positives (healthy but positive test)\")\n",
    "print(f\"  {n_total_positives:,} total positive tests\")\n",
    "print(f\"\\nOf all positive tests, {n_true_positives}/{n_total_positives} = {n_true_positives/n_total_positives:.2%} actually have the disease\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Implement a General Bayes Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_theorem(p_b_given_a, p_a, p_b_given_not_a):\n",
    "    \"\"\"\n",
    "    Calculate P(A|B) using Bayes' theorem.\n",
    "    \n",
    "    Parameters:\n",
    "        p_b_given_a: P(B|A) - likelihood\n",
    "        p_a: P(A) - prior\n",
    "        p_b_given_not_a: P(B|Â¬A)\n",
    "    \n",
    "    Returns:\n",
    "        P(A|B) - posterior\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "\n",
    "# Test with medical example\n",
    "result = bayes_theorem(\n",
    "    p_b_given_a=0.99,      # P(Positive | Disease)\n",
    "    p_a=0.01,              # P(Disease)\n",
    "    p_b_given_not_a=0.05   # P(Positive | No Disease)\n",
    ")\n",
    "print(f\"P(Disease | Positive) = {result:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Updating Beliefs with New Evidence\n",
    "\n",
    "Bayes' theorem is powerful for updating beliefs as new evidence arrives.\n",
    "\n",
    "**Scenario**: Someone tests positive. Then they take a second, independent test and it's also positive. What's the probability they have the disease now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# After first positive test:\n",
    "p_disease_after_first = bayes_theorem(0.99, 0.01, 0.05)\n",
    "print(f\"After 1st positive test: P(Disease) = {p_disease_after_first:.4f}\")\n",
    "\n",
    "# Use this as the new prior for the second test\n",
    "p_disease_after_second = # TODO: Apply Bayes again with updated prior\n",
    "print(f\"After 2nd positive test: P(Disease) = {p_disease_after_second:.4f}\")\n",
    "\n",
    "# What about after a third positive test?\n",
    "p_disease_after_third = # TODO\n",
    "print(f\"After 3rd positive test: P(Disease) = {p_disease_after_third:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how probability updates with each positive test\n",
    "\n",
    "def simulate_sequential_tests(prior, n_tests, sensitivity=0.99, false_positive_rate=0.05):\n",
    "    \"\"\"\n",
    "    Simulate n sequential positive tests and return the posterior after each.\n",
    "    \"\"\"\n",
    "    posteriors = [prior]\n",
    "    current_prior = prior\n",
    "    \n",
    "    for _ in range(n_tests):\n",
    "        posterior = bayes_theorem(sensitivity, current_prior, false_positive_rate)\n",
    "        posteriors.append(posterior)\n",
    "        current_prior = posterior\n",
    "    \n",
    "    return posteriors\n",
    "\n",
    "\n",
    "posteriors = simulate_sequential_tests(0.01, 10)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(len(posteriors)), posteriors, 'bo-', markersize=10)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='50% threshold')\n",
    "plt.axhline(y=0.95, color='g', linestyle='--', alpha=0.5, label='95% threshold')\n",
    "plt.xlabel('Number of Positive Tests')\n",
    "plt.ylabel('P(Disease)')\n",
    "plt.title('Belief Update with Sequential Positive Tests')\n",
    "plt.legend()\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.xticks(range(len(posteriors)))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Find how many tests needed for >95% confidence\n",
    "for i, p in enumerate(posteriors):\n",
    "    if p > 0.95:\n",
    "        print(f\"Need {i} positive tests to reach >95% confidence\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Build a Naive Bayes Spam Classifier (From Scratch!)\n",
    "\n",
    "This is the hands-on project from your study plan: \"Implement Bayes' theorem from scratch for a simple spam classifier (just the math, no sklearn)\"\n",
    "\n",
    "### How Naive Bayes Classification Works:\n",
    "\n",
    "Given a message with words $w_1, w_2, ..., w_n$, we want to find:\n",
    "\n",
    "$$P(Spam | w_1, w_2, ..., w_n)$$\n",
    "\n",
    "Using Bayes:\n",
    "\n",
    "$$P(Spam | words) \\propto P(words | Spam) \\cdot P(Spam)$$\n",
    "\n",
    "The \"naive\" assumption: words are independent given the class:\n",
    "\n",
    "$$P(words | Spam) = P(w_1|Spam) \\cdot P(w_2|Spam) \\cdot ... \\cdot P(w_n|Spam)$$\n",
    "\n",
    "### Exercise 4.1: Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data: labeled emails\n",
    "training_data = [\n",
    "    # (message, is_spam)\n",
    "    (\"free money now\", True),\n",
    "    (\"win free lottery prize\", True),\n",
    "    (\"click here for free offer\", True),\n",
    "    (\"urgent action required free money\", True),\n",
    "    (\"free free free winner\", True),\n",
    "    (\"claim your prize now\", True),\n",
    "    (\"limited time offer free\", True),\n",
    "    (\"congratulations you won\", True),\n",
    "    (\"meeting tomorrow at noon\", False),\n",
    "    (\"can we discuss the project\", False),\n",
    "    (\"here is the report you requested\", False),\n",
    "    (\"lunch meeting on friday\", False),\n",
    "    (\"please review the attached document\", False),\n",
    "    (\"quarterly report is ready\", False),\n",
    "    (\"team meeting at three\", False),\n",
    "    (\"project deadline reminder\", False),\n",
    "    (\"budget review meeting\", False),\n",
    "    (\"status update on project\", False),\n",
    "]\n",
    "\n",
    "print(f\"Training set: {len(training_data)} emails\")\n",
    "print(f\"  Spam: {sum(1 for _, is_spam in training_data if is_spam)}\")\n",
    "print(f\"  Not spam: {sum(1 for _, is_spam in training_data if not is_spam)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Calculate Prior Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Calculate P(Spam) and P(Not Spam)\n",
    "n_spam = # TODO\n",
    "n_not_spam = # TODO\n",
    "n_total = len(training_data)\n",
    "\n",
    "p_spam = # TODO\n",
    "p_not_spam = # TODO\n",
    "\n",
    "print(f\"Prior probabilities:\")\n",
    "print(f\"  P(Spam) = {p_spam:.4f}\")\n",
    "print(f\"  P(Not Spam) = {p_not_spam:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.3: Calculate Word Likelihoods\n",
    "\n",
    "For each word, we need:\n",
    "- P(word | Spam): How often does this word appear in spam?\n",
    "- P(word | Not Spam): How often does this word appear in not-spam?\n",
    "\n",
    "**Important**: We'll use Laplace smoothing to handle words that might not appear in one class:\n",
    "\n",
    "$$P(word|class) = \\frac{count(word, class) + 1}{total\\_words\\_in\\_class + vocabulary\\_size}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(message):\n",
    "    \"\"\"Simple tokenization: lowercase and split on spaces.\"\"\"\n",
    "    return message.lower().split()\n",
    "\n",
    "\n",
    "class NaiveBayesSpamClassifier:\n",
    "    def __init__(self):\n",
    "        self.p_spam = 0\n",
    "        self.p_not_spam = 0\n",
    "        self.word_probs_spam = {}  # P(word | Spam)\n",
    "        self.word_probs_not_spam = {}  # P(word | Not Spam)\n",
    "        self.vocabulary = set()\n",
    "    \n",
    "    def train(self, training_data):\n",
    "        \"\"\"\n",
    "        Train the classifier on labeled data.\n",
    "        \n",
    "        Parameters:\n",
    "            training_data: List of (message, is_spam) tuples\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Step 1: Calculate prior probabilities\n",
    "        spam_messages = [msg for msg, is_spam in training_data if is_spam]\n",
    "        not_spam_messages = [msg for msg, is_spam in training_data if not is_spam]\n",
    "        \n",
    "        self.p_spam = # TODO\n",
    "        self.p_not_spam = # TODO\n",
    "        \n",
    "        # Step 2: Count word frequencies in each class\n",
    "        spam_word_counts = Counter()\n",
    "        not_spam_word_counts = Counter()\n",
    "        \n",
    "        for msg in spam_messages:\n",
    "            words = tokenize(msg)\n",
    "            spam_word_counts.update(words)\n",
    "            self.vocabulary.update(words)\n",
    "        \n",
    "        for msg in not_spam_messages:\n",
    "            words = tokenize(msg)\n",
    "            not_spam_word_counts.update(words)\n",
    "            self.vocabulary.update(words)\n",
    "        \n",
    "        # Step 3: Calculate P(word | class) with Laplace smoothing\n",
    "        total_spam_words = sum(spam_word_counts.values())\n",
    "        total_not_spam_words = sum(not_spam_word_counts.values())\n",
    "        vocab_size = len(self.vocabulary)\n",
    "        \n",
    "        for word in self.vocabulary:\n",
    "            # Laplace smoothing: (count + 1) / (total + vocab_size)\n",
    "            self.word_probs_spam[word] = # TODO\n",
    "            self.word_probs_not_spam[word] = # TODO\n",
    "    \n",
    "    def predict_proba(self, message):\n",
    "        \"\"\"\n",
    "        Calculate P(Spam | message) and P(Not Spam | message).\n",
    "        \n",
    "        Returns:\n",
    "            (p_spam_given_message, p_not_spam_given_message)\n",
    "        \"\"\"\n",
    "        words = tokenize(message)\n",
    "        \n",
    "        # Start with log priors (we use log to avoid underflow)\n",
    "        log_p_spam = np.log(self.p_spam)\n",
    "        log_p_not_spam = np.log(self.p_not_spam)\n",
    "        \n",
    "        # Add log likelihoods for each word\n",
    "        for word in words:\n",
    "            if word in self.vocabulary:\n",
    "                log_p_spam += np.log(self.word_probs_spam[word])\n",
    "                log_p_not_spam += np.log(self.word_probs_not_spam[word])\n",
    "            # If word not in vocabulary, we skip it (or could use smoothing)\n",
    "        \n",
    "        # Convert back from log space and normalize\n",
    "        # YOUR CODE HERE\n",
    "        # Use the log-sum-exp trick for numerical stability:\n",
    "        # P(spam|msg) = exp(log_p_spam) / (exp(log_p_spam) + exp(log_p_not_spam))\n",
    "        \n",
    "        max_log = max(log_p_spam, log_p_not_spam)\n",
    "        p_spam_unnorm = np.exp(log_p_spam - max_log)\n",
    "        p_not_spam_unnorm = np.exp(log_p_not_spam - max_log)\n",
    "        \n",
    "        total = p_spam_unnorm + p_not_spam_unnorm\n",
    "        \n",
    "        return p_spam_unnorm / total, p_not_spam_unnorm / total\n",
    "    \n",
    "    def predict(self, message):\n",
    "        \"\"\"Predict whether message is spam.\"\"\"\n",
    "        p_spam, p_not_spam = self.predict_proba(message)\n",
    "        return p_spam > p_not_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "classifier = NaiveBayesSpamClassifier()\n",
    "classifier.train(training_data)\n",
    "\n",
    "print(\"Classifier trained!\")\n",
    "print(f\"Vocabulary size: {len(classifier.vocabulary)}\")\n",
    "print(f\"\\nSample word probabilities:\")\n",
    "for word in ['free', 'meeting', 'project', 'money']:\n",
    "    if word in classifier.vocabulary:\n",
    "        print(f\"  '{word}': P(word|spam)={classifier.word_probs_spam[word]:.4f}, P(word|not_spam)={classifier.word_probs_not_spam[word]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.4: Test the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test messages\n",
    "test_messages = [\n",
    "    \"free money for you\",\n",
    "    \"meeting about the project tomorrow\",\n",
    "    \"you won a free prize\",\n",
    "    \"please review the budget report\",\n",
    "    \"click here now winner\",\n",
    "    \"team lunch on friday\",\n",
    "    \"free offer limited time\",\n",
    "    \"quarterly review meeting\"\n",
    "]\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(\"=\" * 60)\n",
    "for msg in test_messages:\n",
    "    p_spam, p_not_spam = classifier.predict_proba(msg)\n",
    "    prediction = \"SPAM\" if classifier.predict(msg) else \"NOT SPAM\"\n",
    "    print(f\"{msg[:40]:<40} | P(spam)={p_spam:.2%} | {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.5: Analyze Which Words Are Most \"Spammy\"\n",
    "\n",
    "Calculate the ratio P(word|spam) / P(word|not_spam) for each word to find the strongest spam indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Calculate spam ratio for each word\n",
    "word_spam_ratios = {}\n",
    "for word in classifier.vocabulary:\n",
    "    ratio = # TODO: P(word|spam) / P(word|not_spam)\n",
    "    word_spam_ratios[word] = ratio\n",
    "\n",
    "# Sort by ratio\n",
    "sorted_words = sorted(word_spam_ratios.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Most 'spammy' words (high P(word|spam) / P(word|not_spam) ratio):\")\n",
    "for word, ratio in sorted_words[:10]:\n",
    "    print(f\"  {word}: {ratio:.2f}x more likely in spam\")\n",
    "\n",
    "print(\"\\nLeast 'spammy' words (low ratio):\")\n",
    "for word, ratio in sorted_words[-10:]:\n",
    "    print(f\"  {word}: {1/ratio:.2f}x more likely in not-spam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Calculate Conditional Probabilities on Real Data\n",
    "\n",
    "### Exercise 5.1: Work with a Real Dataset\n",
    "\n",
    "Let's use a dataset with multiple categorical variables and practice calculating various conditional probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset simulating customer behavior\n",
    "np.random.seed(42)\n",
    "n_customers = 5000\n",
    "\n",
    "# Customer attributes\n",
    "age_group = np.random.choice(['18-25', '26-35', '36-50', '50+'], n_customers, p=[0.2, 0.35, 0.3, 0.15])\n",
    "membership = np.random.choice(['Free', 'Basic', 'Premium'], n_customers, p=[0.5, 0.35, 0.15])\n",
    "\n",
    "# Purchase behavior depends on age and membership\n",
    "def get_purchase_prob(age, mem):\n",
    "    base = 0.1\n",
    "    if age == '26-35' or age == '36-50':\n",
    "        base += 0.1\n",
    "    if mem == 'Basic':\n",
    "        base += 0.15\n",
    "    elif mem == 'Premium':\n",
    "        base += 0.35\n",
    "    return min(base, 0.9)\n",
    "\n",
    "made_purchase = np.array([np.random.random() < get_purchase_prob(a, m) \n",
    "                          for a, m in zip(age_group, membership)])\n",
    "\n",
    "customers = pd.DataFrame({\n",
    "    'age_group': age_group,\n",
    "    'membership': membership,\n",
    "    'made_purchase': made_purchase\n",
    "})\n",
    "\n",
    "print(\"Customer Dataset:\")\n",
    "print(customers.head(10))\n",
    "print(f\"\\nTotal customers: {len(customers)}\")\n",
    "print(f\"Purchase rate: {customers['made_purchase'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Question 1: What is P(Purchase | Premium membership)?\n",
    "p_purchase_given_premium = # TODO\n",
    "print(f\"P(Purchase | Premium) = {p_purchase_given_premium:.4f}\")\n",
    "\n",
    "# Question 2: What is P(Premium | Purchase)?\n",
    "p_premium_given_purchase = # TODO\n",
    "print(f\"P(Premium | Purchase) = {p_premium_given_purchase:.4f}\")\n",
    "\n",
    "# Question 3: Calculate P(Purchase | Age Group) for all age groups\n",
    "print(\"\\nP(Purchase | Age Group):\")\n",
    "for age in ['18-25', '26-35', '36-50', '50+']:\n",
    "    p = # TODO\n",
    "    print(f\"  {age}: {p:.4f}\")\n",
    "\n",
    "# Question 4: What is P(Purchase | Premium AND 26-35)?\n",
    "p_purchase_given_premium_and_2635 = # TODO\n",
    "print(f\"\\nP(Purchase | Premium AND 26-35) = {p_purchase_given_premium_and_2635:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2: Verify Bayes' Theorem with Real Data\n",
    "\n",
    "Use the customer data to verify that Bayes' theorem gives the same answer as direct calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll verify P(Premium | Purchase) using Bayes' theorem\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Direct calculation (already done above)\n",
    "direct_result = p_premium_given_purchase\n",
    "\n",
    "# Using Bayes: P(Premium|Purchase) = P(Purchase|Premium) * P(Premium) / P(Purchase)\n",
    "p_purchase_given_premium = # TODO\n",
    "p_premium = # TODO  \n",
    "p_purchase = # TODO\n",
    "\n",
    "bayes_result = # TODO\n",
    "\n",
    "print(\"Verifying Bayes' Theorem:\")\n",
    "print(f\"  Direct calculation: P(Premium|Purchase) = {direct_result:.6f}\")\n",
    "print(f\"  Using Bayes' theorem: P(Premium|Purchase) = {bayes_result:.6f}\")\n",
    "print(f\"  Match: {np.isclose(direct_result, bayes_result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Probability vs. Likelihood\n",
    "\n",
    "This is an important distinction that StatQuest covers well.\n",
    "\n",
    "- **Probability**: Given a distribution with known parameters, what's the chance of seeing certain data?\n",
    "- **Likelihood**: Given the data, how likely is it that the data came from a distribution with certain parameters?\n",
    "\n",
    "### Exercise 6.1: Understanding the Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Probability question:\n",
    "# \"If heights are normally distributed with mean=170, std=10,\n",
    "#  what's the probability of someone being between 165 and 175?\"\n",
    "\n",
    "prob = stats.norm.cdf(175, loc=170, scale=10) - stats.norm.cdf(165, loc=170, scale=10)\n",
    "print(f\"Probability of height between 165-175 (given Î¼=170, Ïƒ=10): {prob:.4f}\")\n",
    "\n",
    "# Likelihood question:\n",
    "# \"Given we observed heights [168, 172, 169, 175, 171],\n",
    "#  how likely is it that Î¼=170 (vs Î¼=165)?\"\n",
    "\n",
    "observed_heights = np.array([168, 172, 169, 175, 171])\n",
    "\n",
    "# Calculate likelihood for different means\n",
    "def log_likelihood(data, mean, std=10):\n",
    "    \"\"\"Calculate log-likelihood of data under Normal(mean, std).\"\"\"\n",
    "    return np.sum(stats.norm.logpdf(data, loc=mean, scale=std))\n",
    "\n",
    "ll_mean_170 = log_likelihood(observed_heights, mean=170)\n",
    "ll_mean_165 = log_likelihood(observed_heights, mean=165)\n",
    "ll_mean_175 = log_likelihood(observed_heights, mean=175)\n",
    "\n",
    "print(f\"\\nLog-likelihood of observed data:\")\n",
    "print(f\"  If Î¼=165: {ll_mean_165:.2f}\")\n",
    "print(f\"  If Î¼=170: {ll_mean_170:.2f}\")\n",
    "print(f\"  If Î¼=175: {ll_mean_175:.2f}\")\n",
    "print(f\"\\nMost likely Î¼ among these: 170 (highest log-likelihood)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize likelihood as a function of the mean parameter\n",
    "\n",
    "means = np.linspace(160, 180, 100)\n",
    "log_likelihoods = [log_likelihood(observed_heights, m) for m in means]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(means, log_likelihoods)\n",
    "plt.axvline(x=np.mean(observed_heights), color='r', linestyle='--', \n",
    "            label=f'Sample mean = {np.mean(observed_heights):.1f}')\n",
    "plt.xlabel('Mean (Î¼)')\n",
    "plt.ylabel('Log-Likelihood')\n",
    "plt.title('Likelihood of Different Means Given Observed Data')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Maximum likelihood estimate\n",
    "mle_mean = means[np.argmax(log_likelihoods)]\n",
    "print(f\"Maximum Likelihood Estimate of Î¼: {mle_mean:.1f}\")\n",
    "print(f\"Sample mean: {np.mean(observed_heights):.1f}\")\n",
    "print(\"(They should be equal for the normal distribution!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: In your own words, explain the difference between probability and likelihood.\n",
    "\n",
    "**Your answer**:\n",
    "- Probability: \n",
    "- Likelihood: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Week 2 Milestone Check\n",
    "\n",
    "### Exercise: Explain P(A|B) and Compute It\n",
    "\n",
    "This is your Week 2 milestone! Complete this without looking anything up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Explain in your own words**\n",
    "\n",
    "What does P(A|B) mean? Provide a concrete example.\n",
    "\n",
    "**Your explanation**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: Compute it manually**\n",
    "\n",
    "Given the following data about students:\n",
    "- 60% of students study computer science (CS)\n",
    "- 30% of students are in the honors program\n",
    "- 20% of students are both CS majors AND in the honors program\n",
    "\n",
    "Calculate:\n",
    "1. P(Honors | CS) - Given a student is CS, what's the probability they're in honors?\n",
    "2. P(CS | Honors) - Given a student is in honors, what's the probability they're CS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Given:\n",
    "p_cs = 0.60\n",
    "p_honors = 0.30\n",
    "p_cs_and_honors = 0.20\n",
    "\n",
    "# Calculate:\n",
    "p_honors_given_cs = # TODO: Use the formula P(A|B) = P(Aâˆ©B) / P(B)\n",
    "p_cs_given_honors = # TODO\n",
    "\n",
    "print(f\"P(Honors | CS) = {p_honors_given_cs:.4f}\")\n",
    "print(f\"P(CS | Honors) = {p_cs_given_honors:.4f}\")\n",
    "\n",
    "# Interpretation:\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  {p_honors_given_cs:.1%} of CS students are in the honors program\")\n",
    "print(f\"  {p_cs_given_honors:.1%} of honors students are CS majors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus Challenges\n",
    "\n",
    "### Bonus 1: Monty Hall Problem\n",
    "\n",
    "Simulate the famous Monty Hall problem and prove that switching is the better strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monty_hall_simulation(n_games=10000, switch=True):\n",
    "    \"\"\"\n",
    "    Simulate the Monty Hall problem.\n",
    "    \n",
    "    Rules:\n",
    "    1. There are 3 doors, one has a car, two have goats\n",
    "    2. You pick a door\n",
    "    3. Monty opens a door with a goat (not your door, not the car door)\n",
    "    4. You can switch to the other unopened door or stay\n",
    "    \n",
    "    Parameters:\n",
    "        n_games: Number of games to simulate\n",
    "        switch: If True, always switch; if False, always stay\n",
    "    \n",
    "    Returns:\n",
    "        Win rate\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "\n",
    "# Run simulations\n",
    "n_games = 100000\n",
    "win_rate_stay = monty_hall_simulation(n_games, switch=False)\n",
    "win_rate_switch = monty_hall_simulation(n_games, switch=True)\n",
    "\n",
    "print(f\"Monty Hall Simulation ({n_games:,} games):\")\n",
    "print(f\"  Win rate if you STAY:   {win_rate_stay:.2%}\")\n",
    "print(f\"  Win rate if you SWITCH: {win_rate_switch:.2%}\")\n",
    "print(f\"\\nSwitching is {win_rate_switch/win_rate_stay:.1f}x better!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 2: Extend the Spam Classifier\n",
    "\n",
    "Improve the Naive Bayes classifier by:\n",
    "1. Adding more training data\n",
    "2. Implementing bigrams (pairs of consecutive words)\n",
    "3. Adding a `score_importance` method that shows which words most influenced a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE - Extend the classifier\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Week 2 Checkpoint\n",
    "\n",
    "Before moving to Week 3, make sure you can:\n",
    "\n",
    "- [ ] Calculate joint, marginal, and conditional probabilities from a dataset\n",
    "- [ ] **Explain what P(A|B) means and compute it manually** (MILESTONE!)\n",
    "- [ ] Explain why P(A|B) â‰  P(B|A) with a concrete example\n",
    "- [ ] Apply Bayes' theorem to update probabilities with new evidence\n",
    "- [ ] Explain the medical testing paradox (why positive test â‰  high probability of disease)\n",
    "- [ ] Implement a simple Naive Bayes classifier from scratch\n",
    "- [ ] Explain the difference between probability and likelihood\n",
    "\n",
    "---\n",
    "\n",
    "**Great work completing Week 2! ðŸŽ‰**\n",
    "\n",
    "Next week: Hypothesis Testing & P-values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
